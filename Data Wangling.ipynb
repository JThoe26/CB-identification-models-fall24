{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afa8b240",
   "metadata": {},
   "source": [
    "# Parsing Social Media API's into CSV's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea4fca3",
   "metadata": {},
   "source": [
    "### General: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "090a5e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is a software library written for the Python programming language for data manipulation and analysis.\n",
    "import pandas as pd\n",
    "# NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "import numpy as np\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c8c0b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    \"\"\"\n",
    "    Remove all special characters from the given text.\n",
    "    :param text: The input text string.\n",
    "    :return: Cleaned text string with only alphanumeric characters and spaces.\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        text = text.replace(\"&#39;\", \"'\").replace(\"ï¿½\", \"\")\n",
    "        cleaned_text = re.sub(r'[^A-Za-z0-9\\s]+', '', text)\n",
    "        return cleaned_text\n",
    "    return '' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d2c9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of cyberbullying keywords (can be expanded)\n",
    "cyberbullying_keywords = [\n",
    "    \"loser\", \"idiot\", \"stupid\", \"ugly\", \"kill\", \"dumb\", \"hate\", \"trash\", \n",
    "    \"fat\", \"moron\", \"freak\", \"retard\", \"bitch\"\n",
    "]\n",
    "\n",
    "# Text speak dictionary to expand common abbreviations\n",
    "text_speak_dict = {\n",
    "    \"u\": \"you\",\n",
    "    \"ur\": \"your\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lmao\": \"laughing my ass off\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"idk\": \"i don't know\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"gr8\": \"great\",\n",
    "    \"wtf\": \"what the f***\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"fml\": \"f*** my life\"\n",
    "    # Add more as needed\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2965ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to expand text speak using regex\n",
    "def expand_text_speak(text):\n",
    "    \"\"\"\n",
    "    Replace text speak abbreviations with their full forms using regex.\n",
    "    :param text: The input text string.\n",
    "    :return: Text with expanded abbreviations.\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        # Replace each text speak abbreviation using the dictionary\n",
    "        for abbrev, full_form in text_speak_dict.items():\n",
    "            text = re.sub(rf'\\b{abbrev}\\b', full_form, text, flags=re.IGNORECASE)\n",
    "        return text\n",
    "    return ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8a92721",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to label comments as \"Cyberbullying\" or \"Not Cyberbullying\"\n",
    "def label_comment(text):\n",
    "    # Clean the text by removing special characters and expanding text speak\n",
    "    cleaned_text = remove_special_characters(text)\n",
    "    expanded_text = expand_text_speak(cleaned_text)\n",
    "    \n",
    "    # Check for any cyberbullying keywords in the expanded text\n",
    "    if any(keyword in expanded_text.lower() for keyword in cyberbullying_keywords):\n",
    "        return \"Cyberbullying\"\n",
    "    return \"Not Cyberbullying\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b791ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to read comments from CSV, label them, and save to a new CSV\n",
    "def label_comments_from_csv(input_csv: str, output_csv: str):\n",
    "    \"\"\"\n",
    "    Read comments from a CSV, label them, and save the labeled data to a new CSV.\n",
    "    \n",
    "    :param input_csv: Path to the input CSV file containing comments.\n",
    "    :param output_csv: Path to the output CSV file for labeled comments.\n",
    "    \"\"\"\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(\"csv is empty\")\n",
    "    \n",
    "    df.columns = ['Comment']\n",
    "    # Apply labeling function to each comment\n",
    "    df['Label'] = df['Comment'].apply(label_comment)\n",
    "    df['Comment'] = df['Comment'].apply(remove_special_characters)\n",
    "    # Save the labeled data to a new CSV file\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Labeled comments saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "724327b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/CSVName.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ff4faca5e382>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcsv_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"data/CSVName.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data/CSVName.csv\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcsv_files\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Read the CSV file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mdf_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Append the DataFrame to the list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\21AhmedU\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\21AhmedU\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\21AhmedU\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\21AhmedU\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\21AhmedU\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\21AhmedU\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\21AhmedU\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/CSVName.csv'"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "csv_files = [\"data/CSVName.csv\", \"data/CSVName.csv\"]\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)  # Read the CSV file\n",
    "    df_list.append(df)  # Append the DataFrame to the list\n",
    "\n",
    "# Concatenate all DataFrames in the list into one DataFrame\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "df_t = merged_df.apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n",
    "df_t.to_csv('merged_output.csv', index=False)\n",
    "df_t.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "063534cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled comments saved to labeled_comments.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This might be the most iconic video of 2023</td>\n",
       "      <td>Not Cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey gurl i know you made mistakes gurl but its ok gurl i forgive you because i know that if i made a mistake i would want to be forgiven so gurl i want you to know that Jesus really loves you and that you can come to him as you already are and he can help us all oki love ya gurl for always being funny you have an incredible talent I just want you to know that Jesus cares for you and He wants to get to know u ok</td>\n",
       "      <td>Not Cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Listen Ive been a fan since miranda sings and I didnt catch that till lateat least you tried to keep contact with your fansIll take a pair of your underwear anyday lmao  I dont believe youre one bit racist or a part of the pedophile machine that runs America  Stay strong lady seriously I dont understand what it is to be famous and lose so many fans over some stupid shit Im sorry you had to suffer this ridiculous mess And theyll find someone new to tear apart and Ill applaud your come back too</td>\n",
       "      <td>Cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guys YN she is a comedian its her job to make videos like this and try r thing with her sending stuff to fans shes a comedian and like tf is she supposed to do idc what the internet is were all humans and if she did do bad stuff its in the future everyone makes mistakes and although people make bigger ones Its sad to think of people who see her that way bc I still love Colleen</td>\n",
       "      <td>Not Cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Like this if your watching in 2024</td>\n",
       "      <td>Not Cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Comment  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                        This might be the most iconic video of 2023   \n",
       "1                                                                                     Hey gurl i know you made mistakes gurl but its ok gurl i forgive you because i know that if i made a mistake i would want to be forgiven so gurl i want you to know that Jesus really loves you and that you can come to him as you already are and he can help us all oki love ya gurl for always being funny you have an incredible talent I just want you to know that Jesus cares for you and He wants to get to know u ok   \n",
       "2  Listen Ive been a fan since miranda sings and I didnt catch that till lateat least you tried to keep contact with your fansIll take a pair of your underwear anyday lmao  I dont believe youre one bit racist or a part of the pedophile machine that runs America  Stay strong lady seriously I dont understand what it is to be famous and lose so many fans over some stupid shit Im sorry you had to suffer this ridiculous mess And theyll find someone new to tear apart and Ill applaud your come back too   \n",
       "3                                                                                                                        Guys YN she is a comedian its her job to make videos like this and try r thing with her sending stuff to fans shes a comedian and like tf is she supposed to do idc what the internet is were all humans and if she did do bad stuff its in the future everyone makes mistakes and although people make bigger ones Its sad to think of people who see her that way bc I still love Colleen   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Like this if your watching in 2024   \n",
       "\n",
       "               Label  \n",
       "0  Not Cyberbullying  \n",
       "1  Not Cyberbullying  \n",
       "2      Cyberbullying  \n",
       "3  Not Cyberbullying  \n",
       "4  Not Cyberbullying  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_csv_file = 'merged_output.csv'  # Path to your existing comments CSV\n",
    "output_csv_file = 'labeled_comments.csv'  # Path to save the labeled comments\n",
    "label_comments_from_csv(input_csv_file, output_csv_file)\n",
    "df = pd.read_csv(output_csv_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be37283c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8cf082e63a9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Apply the function to create new binary columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mkeyword_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Comment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyword_presence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Concatenate the new binary columns to the original DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def keyword_presence(text):\n",
    "    text = text.lower()  # Convert to lowercase for case-insensitive matching\n",
    "    return {keyword: int(keyword in text) for keyword in cyberbullying_keywords}\n",
    "\n",
    "# Apply the function to create new binary columns\n",
    "keyword_columns = df['Comment'].apply(keyword_presence).apply(pd.Series)\n",
    "\n",
    "# Concatenate the new binary columns to the original DataFrame\n",
    "df = pd.concat([df, keyword_columns], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
