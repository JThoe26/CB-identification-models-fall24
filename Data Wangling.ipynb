{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afa8b240",
   "metadata": {},
   "source": [
    "# Parsing Social Media API's into CSV's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea4fca3",
   "metadata": {},
   "source": [
    "### General: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "090a5e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is a software library written for the Python programming language for data manipulation and analysis.\n",
    "import pandas as pd\n",
    "# NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "import numpy as np\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c8c0b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    \"\"\"\n",
    "    Remove all special characters from the given text.\n",
    "    :param text: The input text string.\n",
    "    :return: Cleaned text string with only alphanumeric characters and spaces.\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        text = text.replace(\"&#39;\", \"'\").replace(\"ï¿½\", \"\")\n",
    "        cleaned_text = re.sub(r'[^A-Za-z0-9\\s]+', '', text)\n",
    "        return cleaned_text\n",
    "    return '' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28d2c9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of cyberbullying keywords (can be expanded)\n",
    "cyberbullying_keywords = [\n",
    "    \"loser\", \"idiot\", \"stupid\", \"ugly\", \"kill\", \"dumb\", \"hate\", \"trash\", \n",
    "    \"fat\", \"moron\", \"freak\", \"retard\", \"bitch\", \"ass\", \"asshole\", \"bitch\", \n",
    "    \"bullshit\",\"cock\", \"cunt\", \"dickhead\", \"dumbass\", \"fuck\", \"hell\", \"jackass\", \n",
    "    \"motherfucker\", \"pussy\", \"shit\", \"twat\", \"gay\", \"lesbian\", \"bisexual\", \"transgenger\",\n",
    "    \"queer\", \"faggot\", \"whore\", \"slut\", \"die\", \"racist\", \"sexist\", \"black\", \"white\",\n",
    "    \"muslim\", \"islam\", \"wtf\", \"lmao\", \"lol\", \"kys\", \"yuck\", \"eww\", \"gross\"\n",
    "    ]\n",
    "\n",
    "# Text speak dictionary to expand common abbreviations\n",
    "text_speak_dict = {\n",
    "    \"u\": \"you\",\n",
    "    \"ur\": \"your\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lmao\": \"laughing my ass off\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"idk\": \"i don't know\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"gr8\": \"great\",\n",
    "    \"wtf\": \"what the f***\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"fml\": \"f*** my life\"\n",
    "    # Add more as needed\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2965ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to expand text speak using regex\n",
    "def expand_text_speak(text):\n",
    "    \"\"\"\n",
    "    Replace text speak abbreviations with their full forms using regex.\n",
    "    :param text: The input text string.\n",
    "    :return: Text with expanded abbreviations.\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        # Replace each text speak abbreviation using the dictionary\n",
    "        for abbrev, full_form in text_speak_dict.items():\n",
    "            text = re.sub(rf'\\b{abbrev}\\b', full_form, text, flags=re.IGNORECASE)\n",
    "        return text\n",
    "    return ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8a92721",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to label comments as \"Cyberbullying\" or \"Not Cyberbullying\"\n",
    "def label_comment(text):\n",
    "    # Clean the text by removing special characters and expanding text speak\n",
    "    cleaned_text = remove_special_characters(text)\n",
    "    expanded_text = expand_text_speak(cleaned_text)\n",
    "    \n",
    "    # Check for any cyberbullying keywords in the expanded text\n",
    "    if any(keyword in expanded_text.lower() for keyword in cyberbullying_keywords):\n",
    "        return \"Cyberbullying\"\n",
    "    return \"Not Cyberbullying\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b791ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to read comments from CSV, label them, and save to a new CSV\n",
    "def label_comments_from_csv(input_csv: str, output_csv: str):\n",
    "    \"\"\"\n",
    "    Read comments from a CSV, label them, and save the labeled data to a new CSV.\n",
    "    \n",
    "    :param input_csv: Path to the input CSV file containing comments.\n",
    "    :param output_csv: Path to the output CSV file for labeled comments.\n",
    "    \"\"\"\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(\"csv is empty\")\n",
    "    \n",
    "    df.columns = ['Comment']\n",
    "    # Apply labeling function to each comment\n",
    "    df['Label'] = df['Comment'].apply(label_comment)\n",
    "    df['Comment'] = df['Comment'].apply(remove_special_characters)\n",
    "    # Save the labeled data to a new CSV file\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Labeled comments saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "724327b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     25934\n",
       "unique    21905\n",
       "top           ðŸ’©\n",
       "freq         44\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = []\n",
    "csv_files = [\"data/AhmedScraped.csv\", \"data/JacksonScraped.csv\",\"data/CyberbullyingCmts_5000.csv\",\"data/SoniaScraped.csv\"]\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)  # Read the CSV file\n",
    "    df_list.append(df)  # Append the DataFrame to the list\n",
    "\n",
    "# Concatenate all DataFrames in the list into one DataFrame\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "df_t = merged_df.apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n",
    "df_t.to_csv('data/merged_output.csv', index=False)\n",
    "df_t.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "063534cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled comments saved to data/labeled_comments.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>they never told me I couldnt sing what in the ariana grande from victorious</td>\n",
       "      <td>Not Cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THEY DIDNT SAY I COULDNT SIIINGGGGG kat from victorious that one episode</td>\n",
       "      <td>Not Cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Youre very brave for having the comment section on</td>\n",
       "      <td>Not Cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i didnt know what her response would be but i never couldve imagined this</td>\n",
       "      <td>Not Cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is so insulting to the victims</td>\n",
       "      <td>Not Cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       Comment  \\\n",
       "0  they never told me I couldnt sing what in the ariana grande from victorious   \n",
       "1     THEY DIDNT SAY I COULDNT SIIINGGGGG kat from victorious that one episode   \n",
       "2                           Youre very brave for having the comment section on   \n",
       "3    i didnt know what her response would be but i never couldve imagined this   \n",
       "4                                          This is so insulting to the victims   \n",
       "\n",
       "               Label  \n",
       "0  Not Cyberbullying  \n",
       "1  Not Cyberbullying  \n",
       "2  Not Cyberbullying  \n",
       "3  Not Cyberbullying  \n",
       "4  Not Cyberbullying  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_csv_file = 'data/merged_output.csv'  # Path to your existing comments CSV\n",
    "output_csv_file = 'data/labeled_comments.csv'  # Path to save the labeled comments\n",
    "label_comments_from_csv(input_csv_file, output_csv_file)\n",
    "df = pd.read_csv(output_csv_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f76f493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "Not Cyberbullying    21487\n",
       "Cyberbullying         4447\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be37283c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_27104\\3703677236.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Comment'].fillna(\"\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['Comment'].fillna(\"\", inplace=True)\n",
    "df['Comment'] = df['Comment'].astype(str)\n",
    "def keyword_presence(text):\n",
    "    text = text.lower()  # Convert to lowercase for case-insensitive matching\n",
    "    return {keyword: int(keyword in text) for keyword in cyberbullying_keywords}\n",
    "\n",
    "# Apply the function to create new binary columns\n",
    "keyword_columns = df['Comment'].apply(keyword_presence).apply(pd.Series)\n",
    "\n",
    "# Concatenate the new binary columns to the original DataFrame\n",
    "df = pd.concat([df, keyword_columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6f23103",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [col for col in df.columns if col != 'Label'] + ['Label']\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17f78538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.to_csv('data/word_to_column.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
