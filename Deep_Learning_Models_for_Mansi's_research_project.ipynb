{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Models"
      ],
      "metadata": {
        "id": "aFgCPEFaYsAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This document contain The deep learning models that were created and tested for this project."
      ],
      "metadata": {
        "id": "K4ctCXvVYyv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "HHlr7LENZCl1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qt1-aMUOv5Um"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import resample\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Bidirectional, LSTM, GRU\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolutional Neural Network"
      ],
      "metadata": {
        "id": "ZeX7epXQZBdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This contained the up-sampleing work done for this model along with the creation of the model."
      ],
      "metadata": {
        "id": "qJ4KW3UDZSe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('labeled_comments.csv')\n",
        "minority_class = df[df['Label'] == 'Cyberbullying']\n",
        "majority_class = df[df['Label'] == 'Not Cyberbullying']\n",
        "# Upsample the minority class\n",
        "minority_upsampled = resample(minority_class, replace=True, n_samples=len(majority_class), random_state=42)\n",
        "\n",
        "# Combine the upsampled minority class with the majority class\n",
        "balanced_data = pd.concat([majority_class, minority_upsampled])\n",
        "# Ensure comments are strings and handle NaN values\n",
        "balanced_data['Comment'] = balanced_data['Comment'].astype(str).fillna('')\n",
        "# Tokenization and Preprocessing\n",
        "max_words = 10000  # The number of words to consider as features\n",
        "max_len = 100      # The maximum length of each sequence (for padding)\n",
        "\n",
        "# Using Keras Tokenizer to vectorize the text\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(balanced_data['Comment'])\n",
        "\n",
        "# Convert text to sequences\n",
        "sequences = tokenizer.texts_to_sequences(balanced_data['Comment'])\n",
        "\n",
        "# Pad the sequences to ensure uniform input length\n",
        "X = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "# Encode the labels (if they are not binary, you can adjust this for multiclass classification)\n",
        "balanced_data['Label'] = balanced_data['Label'].astype(str)  # Ensuring labels are string-type if needed\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(balanced_data['Label'])\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# CNN Model Architecture\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: Converts words to dense vectors of fixed size\n",
        "model.add(Embedding(input_dim=max_words, output_dim=64, input_length=max_len))\n",
        "\n",
        "# Convolutional layer with a kernel size of 5 and 64 filters\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "\n",
        "# Pooling layer: Reduces the dimensionality\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "# Dense fully connected layer\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Dropout to reduce overfitting\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer: Binary classification (you can adjust for more classes)\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate the model on validation data\n",
        "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
        "print(f'Validation Accuracy: {val_acc}')\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "print(f'Classification Report:\\n{classification_report(y_val, y_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKOjJXahwCrg",
        "outputId": "8485b81c-004b-44a6-d2b9-55fa5dbc7621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m890/890\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.7130 - loss: 0.5349 - val_accuracy: 0.9048 - val_loss: 0.2370\n",
            "Epoch 2/5\n",
            "\u001b[1m890/890\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - accuracy: 0.9444 - loss: 0.1623 - val_accuracy: 0.9408 - val_loss: 0.1686\n",
            "Epoch 3/5\n",
            "\u001b[1m890/890\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 21ms/step - accuracy: 0.9801 - loss: 0.0654 - val_accuracy: 0.9442 - val_loss: 0.2118\n",
            "Epoch 4/5\n",
            "\u001b[1m890/890\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.9917 - loss: 0.0270 - val_accuracy: 0.9441 - val_loss: 0.2308\n",
            "Epoch 5/5\n",
            "\u001b[1m890/890\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.9952 - loss: 0.0162 - val_accuracy: 0.9459 - val_loss: 0.2730\n",
            "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9481 - loss: 0.2642\n",
            "Validation Accuracy: 0.9458813667297363\n",
            "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "[[3418  102]\n",
            " [ 283 3311]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95      3520\n",
            "           1       0.97      0.92      0.95      3594\n",
            "\n",
            "    accuracy                           0.95      7114\n",
            "   macro avg       0.95      0.95      0.95      7114\n",
            "weighted avg       0.95      0.95      0.95      7114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('cnn_text_classification.h5')"
      ],
      "metadata": {
        "id": "Sm4FJ214Zq-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bi-directional Long-Short Term Memory"
      ],
      "metadata": {
        "id": "j9eHa_n_ZtuK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This contained the up-sampleing work done for this model along with the creation of the model."
      ],
      "metadata": {
        "id": "RNb5DHAoZ0p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "# Load the dataset\n",
        "df = pd.read_csv('labeled_comments.csv')\n",
        "minority_class = df[df['Label'] == 'Cyberbullying']\n",
        "majority_class = df[df['Label'] == 'Not Cyberbullying']\n",
        "# Upsample the minority class\n",
        "minority_upsampled = resample(minority_class, replace=True, n_samples=len(majority_class), random_state=42)\n",
        "\n",
        "# Combine the upsampled minority class with the majority class\n",
        "balanced_data = pd.concat([majority_class, minority_upsampled])\n",
        "# Ensure comments are strings and handle NaN values\n",
        "balanced_data['Comment'] = balanced_data['Comment'].astype(str).fillna('')\n",
        "# Tokenization and Preprocessing\n",
        "max_words = 10000  # The number of words to consider as features\n",
        "max_len = 100      # The maximum length of each sequence (for padding)\n",
        "\n",
        "# Using Keras Tokenizer to vectorize the text\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(balanced_data['Comment'])\n",
        "\n",
        "# Convert text to sequences\n",
        "sequences = tokenizer.texts_to_sequences(balanced_data['Comment'])\n",
        "\n",
        "# Pad the sequences to ensure uniform input length\n",
        "X = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "# Encode the labels (if they are not binary, you can adjust this for multiclass classification)\n",
        "balanced_data['Label'] = balanced_data['Label'].astype(str)  # Ensuring labels are string-type if needed\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(balanced_data['Label'])\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# BiLSTM Model Architecture\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: Converts words to dense vectors of fixed size\n",
        "model.add(Embedding(input_dim=max_words, output_dim=64, input_length=max_len))\n",
        "\n",
        "# layer with a kernel 64 filters\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "\n",
        "# Dense fully connected layer\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Dropout to reduce overfitting\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer: Binary classification (you can adjust for more classes)\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate the model on validation data\n",
        "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
        "print(f'Validation Accuracy: {val_acc}')\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "print(f'Classification Report:\\n{classification_report(y_val, y_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc2nVf5Jywp6",
        "outputId": "dea7aa24-7658-4df7-cc88-e3d3a306cd7a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m890/890\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 278ms/step - accuracy: 0.7338 - loss: 0.5128 - val_accuracy: 0.8940 - val_loss: 0.2644\n",
            "Epoch 2/5\n",
            "\u001b[1m890/890\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 226ms/step - accuracy: 0.9333 - loss: 0.1872 - val_accuracy: 0.9265 - val_loss: 0.2172\n",
            "Epoch 3/5\n",
            "\u001b[1m890/890\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 223ms/step - accuracy: 0.9642 - loss: 0.0986 - val_accuracy: 0.9322 - val_loss: 0.2232\n",
            "Epoch 4/5\n",
            "\u001b[1m890/890\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 225ms/step - accuracy: 0.9819 - loss: 0.0557 - val_accuracy: 0.9450 - val_loss: 0.2304\n",
            "Epoch 5/5\n",
            "\u001b[1m890/890\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 224ms/step - accuracy: 0.9905 - loss: 0.0326 - val_accuracy: 0.9460 - val_loss: 0.2283\n",
            "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - accuracy: 0.9483 - loss: 0.2339\n",
            "Validation Accuracy: 0.9460219144821167\n",
            "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step\n",
            "[[3436   84]\n",
            " [ 300 3294]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95      3520\n",
            "           1       0.98      0.92      0.94      3594\n",
            "\n",
            "    accuracy                           0.95      7114\n",
            "   macro avg       0.95      0.95      0.95      7114\n",
            "weighted avg       0.95      0.95      0.95      7114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('BiLSTM_text_classification.h5')"
      ],
      "metadata": {
        "id": "64Zr15Of1xYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bi-Directional Grated Recurrent Units"
      ],
      "metadata": {
        "id": "XcbmaMrFaCjv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This contained the up-sampleing work done for this model along with the creation of the model."
      ],
      "metadata": {
        "id": "3bBVBHycaPk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "# Load the dataset\n",
        "df = pd.read_csv('labeled_comments.csv')\n",
        "minority_class = df[df['Label'] == 'Cyberbullying']\n",
        "majority_class = df[df['Label'] == 'Not Cyberbullying']\n",
        "# Upsample the minority class\n",
        "minority_upsampled = resample(minority_class, replace=True, n_samples=len(majority_class), random_state=42)\n",
        "\n",
        "# Combine the upsampled minority class with the majority class\n",
        "balanced_data = pd.concat([majority_class, minority_upsampled])\n",
        "# Ensure comments are strings and handle NaN values\n",
        "balanced_data['Comment'] = balanced_data['Comment'].astype(str).fillna('')\n",
        "\n",
        "# Tokenization and Preprocessing\n",
        "max_words = 10000  # The number of words to consider as features\n",
        "max_len = 100      # The maximum length of each sequence (for padding)\n",
        "\n",
        "# Using Keras Tokenizer to vectorize the text\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(balanced_data['Comment'])\n",
        "\n",
        "# Convert text to sequences\n",
        "sequences = tokenizer.texts_to_sequences(balanced_data['Comment'])\n",
        "\n",
        "# Pad the sequences to ensure uniform input length\n",
        "X = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "# Encode the labels (if they are not binary, you can adjust this for multiclass classification)\n",
        "balanced_data['Label'] = balanced_data['Label'].astype(str)  # Ensuring labels are string-type if needed\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(balanced_data['Label'])\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# BiGRU Model Architecture\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: Converts words to dense vectors of fixed size\n",
        "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
        "\n",
        "# layer with a kernel 64 filters\n",
        "model.add(Bidirectional(GRU(64, return_sequences=True)))\n",
        "\n",
        "model.add(Bidirectional(GRU(32)))\n",
        "\n",
        "# Dense fully connected layer\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Dropout to reduce overfitting\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer: Binary classification (you can adjust for more classes)\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate the model on validation data\n",
        "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
        "print(f'Validation Accuracy: {val_acc}')\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "print(f'Classification Report:\\n{classification_report(y_val, y_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j8Gw7bt-smJ",
        "outputId": "1ecc7ef6-b9c2-4c26-daba-10e882101416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m890/890\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 263ms/step - accuracy: 0.7410 - loss: 0.5067 - val_accuracy: 0.9040 - val_loss: 0.2481\n",
            "Epoch 2/5\n",
            "\u001b[1m890/890\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 255ms/step - accuracy: 0.9405 - loss: 0.1694 - val_accuracy: 0.9240 - val_loss: 0.2197\n",
            "Epoch 3/5\n",
            "\u001b[1m890/890\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 257ms/step - accuracy: 0.9758 - loss: 0.0744 - val_accuracy: 0.9370 - val_loss: 0.2033\n",
            "Epoch 4/5\n",
            "\u001b[1m890/890\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 263ms/step - accuracy: 0.9880 - loss: 0.0385 - val_accuracy: 0.9425 - val_loss: 0.2370\n",
            "Epoch 5/5\n",
            "\u001b[1m890/890\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 258ms/step - accuracy: 0.9933 - loss: 0.0218 - val_accuracy: 0.9355 - val_loss: 0.3234\n",
            "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.9365 - loss: 0.3182\n",
            "Validation Accuracy: 0.9354793429374695\n",
            "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 51ms/step\n",
            "[[3401  119]\n",
            " [ 340 3254]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.97      0.94      3520\n",
            "           1       0.96      0.91      0.93      3594\n",
            "\n",
            "    accuracy                           0.94      7114\n",
            "   macro avg       0.94      0.94      0.94      7114\n",
            "weighted avg       0.94      0.94      0.94      7114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('BiGRU_text_classification.h5')"
      ],
      "metadata": {
        "id": "h4xYJbw8bEED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the BERT Dataset"
      ],
      "metadata": {
        "id": "Jq7jFqaEbPKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following section contains the CNN model utilizing the Predicted Labels produced from the BERT model."
      ],
      "metadata": {
        "id": "S9XjGr3-bX0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('bert_prediction.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mCGugPZv535h",
        "outputId": "0cb00f3d-ebbc-414d-ae14-63dd735304fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Comment  Label    Predicted_Label\n",
              "0  they never told me I couldnt sing what in the ...      0  Not Cyberbullying\n",
              "1  THEY DIDNT SAY I COULDNT SIIINGGGGG kat from v...      0  Not Cyberbullying\n",
              "2  Youre very brave for having the comment sectio...      0  Not Cyberbullying\n",
              "3  i didnt know what her response would be but i ...      0  Not Cyberbullying\n",
              "4                This is so insulting to the victims      1      Cyberbullying"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-844aee9d-9dba-4aaa-b49b-ac281a85d008\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Label</th>\n",
              "      <th>Predicted_Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>they never told me I couldnt sing what in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Not Cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>THEY DIDNT SAY I COULDNT SIIINGGGGG kat from v...</td>\n",
              "      <td>0</td>\n",
              "      <td>Not Cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Youre very brave for having the comment sectio...</td>\n",
              "      <td>0</td>\n",
              "      <td>Not Cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i didnt know what her response would be but i ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Not Cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This is so insulting to the victims</td>\n",
              "      <td>1</td>\n",
              "      <td>Cyberbullying</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-844aee9d-9dba-4aaa-b49b-ac281a85d008')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-844aee9d-9dba-4aaa-b49b-ac281a85d008 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-844aee9d-9dba-4aaa-b49b-ac281a85d008');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4d95fb4b-8149-4f0c-bc9d-393c6949a9da\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4d95fb4b-8149-4f0c-bc9d-393c6949a9da')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4d95fb4b-8149-4f0c-bc9d-393c6949a9da button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 25934,\n  \"fields\": [\n    {\n      \"column\": \"Comment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21591,\n        \"samples\": [\n          \"Its crazy to see this now that hes lost 250lbs\",\n          \"Hell who can afford Doritos or clubbing in the fkd up economy\",\n          \"a hrefhttpswwwyoutubecomwatchvbuo65dHe53Yampt81121a and stop look at his hair 1945 haircutand rainbow  nails is he a girl\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted_Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Cyberbullying\",\n          \"Not Cyberbullying\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "# Load the dataset\n",
        "minority_class = df[df['Predicted_Label'] == 'Cyberbullying']\n",
        "majority_class = df[df['Predicted_Label'] == 'Not Cyberbullying']\n",
        "# Upsample the minority class\n",
        "minority_upsampled = resample(minority_class, replace=True, n_samples=len(majority_class), random_state=42)\n",
        "\n",
        "# Combine the upsampled minority class with the majority class\n",
        "balanced_data = pd.concat([majority_class, minority_upsampled])\n",
        "# Ensure comments are strings and handle NaN values\n",
        "balanced_data['Comment'] = balanced_data['Comment'].astype(str).fillna('')\n",
        "# Tokenization and Preprocessing\n",
        "max_words = 10000  # The number of words to consider as features\n",
        "max_len = 100      # The maximum length of each sequence (for padding)\n",
        "\n",
        "# Using Keras Tokenizer to vectorize the text\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(balanced_data['Comment'])\n",
        "\n",
        "# Convert text to sequences\n",
        "sequences = tokenizer.texts_to_sequences(balanced_data['Comment'])\n",
        "\n",
        "# Pad the sequences to ensure uniform input length\n",
        "X = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "# Encode the labels (if they are not binary, you can adjust this for multiclass classification)\n",
        "balanced_data['Predicted_Label'] = balanced_data['Predicted_Label'].astype(str)  # Ensuring labels are string-type if needed\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(balanced_data['Predicted_Label'])\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# CNN Model Architecture\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: Converts words to dense vectors of fixed size\n",
        "model.add(Embedding(input_dim=max_words, output_dim=64, input_length=max_len))\n",
        "\n",
        "# Convolutional layer with a kernel size of 5 and 64 filters\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "\n",
        "# Pooling layer: Reduces the dimensionality\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "# Dense fully connected layer\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Dropout to reduce overfitting\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer: Binary classification (you can adjust for more classes)\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate the model on validation data\n",
        "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
        "print(f'Validation Accuracy: {val_acc}')\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "print(f'Classification Report:\\n{classification_report(y_val, y_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV5rXNT85x76",
        "outputId": "bf8de638-2abd-432a-8489-1957acca7c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m886/886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.7246 - loss: 0.5217 - val_accuracy: 0.9168 - val_loss: 0.2238\n",
            "Epoch 2/5\n",
            "\u001b[1m886/886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - accuracy: 0.9466 - loss: 0.1534 - val_accuracy: 0.9397 - val_loss: 0.1711\n",
            "Epoch 3/5\n",
            "\u001b[1m886/886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.9816 - loss: 0.0587 - val_accuracy: 0.9475 - val_loss: 0.1579\n",
            "Epoch 4/5\n",
            "\u001b[1m886/886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.9941 - loss: 0.0222 - val_accuracy: 0.9564 - val_loss: 0.1813\n",
            "Epoch 5/5\n",
            "\u001b[1m886/886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 22ms/step - accuracy: 0.9975 - loss: 0.0102 - val_accuracy: 0.9524 - val_loss: 0.2220\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9513 - loss: 0.2215\n",
            "Validation Accuracy: 0.9524078369140625\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3408  119]\n",
            " [ 218 3336]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.95      3527\n",
            "           1       0.97      0.94      0.95      3554\n",
            "\n",
            "    accuracy                           0.95      7081\n",
            "   macro avg       0.95      0.95      0.95      7081\n",
            "weighted avg       0.95      0.95      0.95      7081\n",
            "\n"
          ]
        }
      ]
    }
  ]
}